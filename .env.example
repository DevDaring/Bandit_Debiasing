# =============================================================================
# Fair-CB Environment Variables
# =============================================================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control

# -----------------------------------------------------------------------------
# HuggingFace Configuration (REQUIRED)
# -----------------------------------------------------------------------------
# Get your token from: https://huggingface.co/settings/tokens
# Required for:
#   - Debk/Multi-CrowS-Pairs (private dataset)
#   - Debk/Indian-Multilingual-Bias-Dataset (private dataset)
#   - meta-llama/Llama-3.2-1B-Instruct (gated model)
#   - google/gemma-2-2b-it (gated model)
HF_TOKEN=your_huggingface_token_here

# Optional: Custom cache directory for models
# HF_HOME=/path/to/custom/cache

# Optional: Disable telemetry
# HF_HUB_DISABLE_TELEMETRY=1

# -----------------------------------------------------------------------------
# Weights & Biases Configuration (Optional)
# -----------------------------------------------------------------------------
# Get your API key from: https://wandb.ai/settings
WANDB_API_KEY=your_wandb_key_here
WANDB_PROJECT=fair-cb-debiasing
WANDB_ENTITY=your_wandb_username_or_team

# Disable W&B logging (set to "true" to disable)
# WANDB_DISABLED=false

# -----------------------------------------------------------------------------
# CUDA Configuration
# -----------------------------------------------------------------------------
# Specify which GPU to use (0-indexed)
CUDA_VISIBLE_DEVICES=0

# Memory allocation settings
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# -----------------------------------------------------------------------------
# Experiment Configuration
# -----------------------------------------------------------------------------
# Random seed for reproducibility
RANDOM_SEED=42

# Maximum samples for quick testing (comment out for full run)
# MAX_TRAIN_SAMPLES=1000
# MAX_EVAL_SAMPLES=200
