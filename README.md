# Fair-CB: Fairness-Aware Contextual Bandits for Multilingual LLM Debiasing

<div align="center">

**Adaptive Multi-Armed Bandit Debiasing Strategy Selection for Multilingual Large Language Models**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

</div>

---

## ğŸ¯ Overview

Fair-CB is a research framework that dynamically selects optimal debiasing interventions for multilingual LLMs using contextual bandit algorithms.

### Key Features

| Feature | Description |
|---------|-------------|
| **Multi-Model Support** | Qwen2.5-1.5B, Llama-3.2-1B, Gemma-2-2B |
| **Multilingual** | English, Hindi, Bengali + code-mixing |
| **Novel Metrics** | IBR (Intersectional Bias Reduction), FAR (Fairness-Aware Regret) |
| **Statistical Rigor** | Bootstrap CIs, paired t-tests, effect sizes |
| **Counterfactual Evaluation** | True regret via all-arm evaluation |

### Models (24GB VRAM Constraint)

| Model | Parameters | VRAM (4-bit) |
|-------|------------|--------------|
| Qwen/Qwen2.5-1.5B-Instruct | 1.5B | ~2.5GB |
| meta-llama/Llama-3.2-1B-Instruct | 1B | ~1.5GB |
| google/gemma-2-2b-it | 2B | ~3.0GB |

### Debiasing Arms (6 Strategies)

| Arm | Strategy | Description |
|-----|----------|-------------|
| 0 | No Intervention | Baseline |
| 1 | Gender Steering | Steering vector for gender bias |
| 2 | Race Steering | Steering vector for race/ethnicity |
| 3 | Religion Steering | Steering vector for religious bias |
| 4 | Prompt Prefix | Fairness-aware prompt modification |
| 5 | Output Adjustment | Post-hoc output debiasing |

---

## ğŸš€ Quick Start

```bash
# Install
pip install -r requirements.txt
python setup.py develop

# Configure
cp .env.example .env
# Add HF_TOKEN to .env

# Run experiment
python scripts/generate_all_results.py --quick  # Test
python scripts/generate_all_results.py          # Full

# Evaluate with metrics
python scripts/evaluate_with_metrics.py --dataset both --generate-latex
```

---

## ğŸ“Š Novel Metrics

### IBR (Intersectional Bias Reduction)

```
IBR = HarmonicMean({reduction_per_category})
Signed_IBR = IBR * (1 - n_worsened/n_total)  # Penalizes bias increases
```

### FAR (Fairness-Aware Regret)

```
FAR = R(T) + Î»Â·V(T)
```
Where R(T) = cumulative regret, V(T) = fairness violations, Î» = weight (default 0.5)

---

## ğŸ“ Project Structure

```
Fair-CB/
â”œâ”€â”€ config/                      # Configuration
â”‚   â””â”€â”€ model_config.py          # Model registry (1.5B/1B/2B)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ theory/                  # Theoretical analysis
â”‚   â”œâ”€â”€ metrics/                 # IBR, FAR, statistical tests
â”‚   â”œâ”€â”€ evaluation/              # Counterfactual evaluator
â”‚   â”œâ”€â”€ crosslingual/            # Transfer analysis
â”‚   â”œâ”€â”€ ablation/                # Ablation framework
â”‚   â””â”€â”€ pipeline/                # Training pipelines
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_all_results.py  # Full experiment suite
â”‚   â””â”€â”€ evaluate_with_metrics.py # IBR/FAR evaluation
â””â”€â”€ docs/
    â””â”€â”€ theoretical_limitations.md  # Documented limitations
```

---

## ğŸ”¬ Theoretical Guarantees

### Regret Bound (LinUCB)

```
R(T) â‰¤ O(dâˆš(KT log(T/Î´)))
```

### Counterfactual Evaluation

For true regret computation, use `CounterfactualEvaluator`:

```python
from src.evaluation import CounterfactualEvaluator

evaluator = CounterfactualEvaluator(n_arms=6)
summary = evaluator.evaluate_dataset(
    samples=test_data,
    arm_executor=run_arm,
    bandit_selector=bandit.select_arm
)
print(f"True Regret: {summary.true_cumulative_regret}")
print(f"Adaptive/Static Ratio: {summary.adaptive_vs_static_ratio}")
```

---

## âš ï¸ Known Limitations

See [docs/theoretical_limitations.md](docs/theoretical_limitations.md) for full details:

1. **LinUCB realizability**: Reward function is not perfectly linear
2. **Non-i.i.d. contexts**: Data is grouped by bias category
3. **24GB VRAM constraint**: Limited to 1-2B parameter models
4. **Regret estimation**: Training uses estimated (not counterfactual) regret

---

## ğŸ“‹ Statistical Reporting

All results include:
- **95% Bootstrap CIs**: `compute_bootstrap_ci()`
- **Paired t-tests**: `compute_paired_ttest()`
- **Effect sizes**: Cohen's d with interpretation

```python
from src.metrics import StatisticalAnalyzer

analyzer = StatisticalAnalyzer()
analyzer.add_results('Fair-CB', scores)
ci = analyzer.get_confidence_interval('Fair-CB')
print(f"Mean: {ci.mean:.4f} [{ci.lower:.4f}, {ci.upper:.4f}]")
```

---

## ğŸ“œ Citation

```bibtex
@article{fair_cb_2026,
  title={Fair-CB: Fairness-Aware Contextual Bandits for Adaptive Multilingual LLM Debiasing},
  author={Your Name},
  journal={Transactions of the Association for Computational Linguistics},
  year={2026}
}
```

---

## ğŸ“„ License

MIT License
